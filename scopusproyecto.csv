"Authors","Author full names","Author(s) ID","Title","Year","Source title","Volume","Issue","Art. No.","Page start","Page end","Page count","Cited by","DOI","Link","Affiliations","Authors with affiliations","Abstract","Author Keywords","Index Keywords","Editors","Publisher","Language of Original Document","Abbreviated Source Title","Document Type","Publication Stage","Open Access","Source","EID"
"Divya D.M.; Karthika Devi M.S.; Ramachandran B.","Divya, D.M. (58420966000); Karthika Devi, M.S. (55091080300); Ramachandran, B. (38961968400)","58420966000; 55091080300; 38961968400","SPEG—Semiotics-Based Panel Extraction from Graphic Novel","2023","Lecture Notes in Electrical Engineering","1007 LNEE","","","315","327","12","0","10.1007/978-981-99-0189-0_23","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161576319&doi=10.1007%2f978-981-99-0189-0_23&partnerID=40&md5=d9376fd53fdbf2c6b15af482dfe09477","Department of Artificial Intelligence and Data Science, R.M.K Engineering College, Kavaraipettai, Tamil Nadu, Chennai, India; Department of Computer Science and Engineering, College of Engineering, Guindy, Anna University, Tamil Nadu, Chennai, India","Divya D.M., Department of Artificial Intelligence and Data Science, R.M.K Engineering College, Kavaraipettai, Tamil Nadu, Chennai, India; Karthika Devi M.S., Department of Computer Science and Engineering, College of Engineering, Guindy, Anna University, Tamil Nadu, Chennai, India; Ramachandran B., Department of Computer Science and Engineering, College of Engineering, Guindy, Anna University, Tamil Nadu, Chennai, India","The researchers of the graphic novels face challenges coping with the graphic novel images as they are associated with the range of designs, layout, text, and actions. These challenges make the content learning and object detection task much more difficult. To overcome this, deep learning approaches are incorporated in several domains through the use of machine learning techniques. A graphic novel is the composition of a text and graphic. To fully analyze the content of the graphic novel, understanding of the story, dialogs, line drawings, characters, and their location is required. Especially in comic analysis, detection of comic characters has been an interesting area as it inculcates adequate understanding of comics. The comparisons between graphic communication and languages are standardized in visual language theory (VLT). The visual language consists of signs that are highly conventionalized, but they vary according to the distribution of where they are positioned inside the panel of the graphic novel strip. The visual morphology uses semiotic references such as motion lines, scopic lines, radial lines, focal lines, spikes, twirls, spirals, and the shapes such as heart and stars. Depending on the location they are placed, the meaning varies. The research studies are focused to identify these conventions and how these signs interact and modify others. In this work, to identify the semiotics at different locations from a graphic novel strip, a custom YOLOv3 detector model is trained followed by the panel extraction. The individual panels are extracted using contour analysis. The trained model could detect the semiotics from the graphic novel images when they are placed around the character of interest with the mean average precision of 75.8%. The proposed method SPEGYOLO extracts the semiotics in the panels of graphic novels and further analysis based on their location and orientation will help the users to apprehend the meaning associated with it. © 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.","Panel extraction; Semiotic references; SPEGYOLO; Visual language theory; YOLOv3 detector model","Deep learning; Extraction; Learning systems; Location; Object detection; Semiotics; Design layout; Detection tasks; Detector modeling; Language theory; Objects detection; Panel extraction; Semiotic reference; SPEGYOLO; Visual language theory; YOLOv3 detector model; Visual languages","Kumar Singh K.; Bajpai M.K.; Sheikh Akbari A.","Springer Science and Business Media Deutschland GmbH","English","Lect. Notes Electr. Eng.","Conference paper","Final","","Scopus","2-s2.0-85161576319"
"Kim M.; Mohanty A.; Kadetotad D.; Wei L.; He X.; Cao Y.; Seo J.-S.","Kim, Minkyu (56969839400); Mohanty, Abinash (56470320800); Kadetotad, Deepak (56109513600); Wei, Luning (57193624402); He, Xiaofei (36164098600); Cao, Yu (35301937800); Seo, Jae-Sun (7401783933)","56969839400; 56470320800; 56109513600; 57193624402; 36164098600; 35301937800; 7401783933","A Real-Time 17-Scale Object Detection Accelerator with Adaptive 2000-Stage Classification in 65 nm CMOS","2019","IEEE Transactions on Circuits and Systems I: Regular Papers","66","10","8741167","3843","3853","10","5","10.1109/TCSI.2019.2921714","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072973325&doi=10.1109%2fTCSI.2019.2921714&partnerID=40&md5=085f1a983a2488e12636b8d1e4d79428","School of Electrical, Computer and Energy Engineering, Arizona State University, Tempe, AZ, United States; College of Computer Science, Zhejiang University, Hangzhou, China","Kim M., School of Electrical, Computer and Energy Engineering, Arizona State University, Tempe, AZ, United States; Mohanty A., School of Electrical, Computer and Energy Engineering, Arizona State University, Tempe, AZ, United States; Kadetotad D., School of Electrical, Computer and Energy Engineering, Arizona State University, Tempe, AZ, United States; Wei L., College of Computer Science, Zhejiang University, Hangzhou, China; He X., College of Computer Science, Zhejiang University, Hangzhou, China; Cao Y., School of Electrical, Computer and Energy Engineering, Arizona State University, Tempe, AZ, United States; Seo J.-S., School of Electrical, Computer and Energy Engineering, Arizona State University, Tempe, AZ, United States","Machine learning has become ubiquitous in applications including object detection, image/video classification, and natural language processing. While machine learning algorithms have been successfully used in many practical applications, accurate, fast, and low-power hardware implementations of such algorithms is still a challenging task, especially for mobile systems such as Internet of Things (IoT), autonomous vehicles, and smart drones. This paper presents an energy-efficient programmable ASIC accelerator for object detection. Our ASIC accelerator supports multi-class (e.g., face, traffic sign, car license plate, and pedestrian) that are programmable, many-object (up to 50) in one image with different sizes (17-scale support with 6 down-/11 up-scaling), and high accuracy (AP of 0.87/0.81/0.72/0.76 for FDDB/AFW/BTSD/Caltech datasets). We designed an integral channel detector with 2,000 classifiers for rigid boosted templates, where the number of stages used for classification can be adaptively controlled depending on the content of the search window. This can be implemented with a more modular hardware, compared to support vector machine (SVM) and deformable parts model (DPM) designs. By jointly optimizing the algorithm and the efficient hardware architecture, the prototype chip implemented in 65nm CMOS demonstrates real-Time object detection of 20-50 frames/s with low power consumption of 22.5-181.7 mW (0.54-1.75 nJ/pixel) at 0.58-1.1 V supply. © 2004-2012 IEEE.","classification; low-power; machine learning; Object detection; real-Time; special-purpose accelerator","Classification (of information); CMOS integrated circuits; Energy efficiency; Internet of things; Learning algorithms; Learning systems; License plates (automobile); Natural language processing systems; Object recognition; Support vector machines; Deformable parts models; Hardware architecture; Image/video classifications; Internet of Things (IOT); Low Power; Low-power consumption; NAtural language processing; Real time; Object detection","","Institute of Electrical and Electronics Engineers Inc.","English","IEEE Trans. Circuits Syst. Regul. Pap.","Article","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-85072973325"
"Shikha N.; Pranav R.; Singh N.R.; Umadevi V.; Hussain M.","Shikha, N. (58178663100); Pranav, R. (22433428500); Singh, Nidhi R (58285477100); Umadevi, V. (35241434900); Hussain, Muzammil (58590314800)","58178663100; 22433428500; 58285477100; 35241434900; 58590314800","Kannada Word Detection in Heterogeneous Scene Images","2023","Proceedings of the 10th International Conference on Signal Processing and Integrated Networks, SPIN 2023","","","","379","383","4","0","10.1109/SPIN57001.2023.10117096","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160008723&doi=10.1109%2fSPIN57001.2023.10117096&partnerID=40&md5=bbfbd842d9dd9b629c677d79e6b39fbd","B.M.S. College of Engineering, Dept. of Computer Science, Bengaluru, India; B.M.S. College of Engineering, Dept. of Electrical and Electronics, Bengaluru, India; B.M.S. College of Engineering, Dept. of Medical Electronics, Bengaluru, India; Tika Data Services Pvt. Ltd., Bengaluru, India","Shikha N., B.M.S. College of Engineering, Dept. of Computer Science, Bengaluru, India; Pranav R., B.M.S. College of Engineering, Dept. of Electrical and Electronics, Bengaluru, India; Singh N.R., B.M.S. College of Engineering, Dept. of Medical Electronics, Bengaluru, India; Umadevi V., B.M.S. College of Engineering, Dept. of Computer Science, Bengaluru, India; Hussain M., Tika Data Services Pvt. Ltd., Bengaluru, India","Text extraction from scene images has started gaining a lot of traction in recent years in the computer vision field as its applications is manifold. One of its sub-categories is scene text detection. Factors like complex backgrounds, curvature, orientation, image quality, and various font styles and sizes makes it a difficult task. Moreover, building a single language scene text detector in a multilingual setting, especially Indian scripts, is more challenging in contrast to a general text detector. In this Work We attempt the task of Kannada text localization as Well as Word detection in natural scenes, Which is underexplored in comparison to other Well-known Indian languages. To achieve this, We fine tune a You Only Look Once (YOLOv4) based object detection model on our Kannada scene text images dataset collected. Experiments on local boards and sign images captured on smartphone, showed a mean average precision of 93.5% and per image average detection speed of 30 milli-seconds; pointing towards real time use and integration With mobile applications.  © 2023 IEEE.","deep learning; kannada; neural network; scene text detection; word detection","Computer vision; Deep learning; Deep learning; ITS applications; Kannada; Neural-networks; Scene image; Scene Text; Scene text detection; Text detection; Text extraction; Word detection; Object detection","Pandey M.K.; Rai J.K.; Kumar P.; Dubey A.K.; Shukla A.K.","Institute of Electrical and Electronics Engineers Inc.","English","Proc. Int. Conf. Signal Process. Integr. Networks, SPIN","Conference paper","Final","","Scopus","2-s2.0-85160008723"
"Shrestha O.K.; Khatiwada S.; Ghimire A.; Rajbhandari B.; Kumar A.V.","Shrestha, Oskar Krishna (58674387900); Khatiwada, Sakar (58674336600); Ghimire, Adarsha (58674352500); Rajbhandari, Bibhuti (58674456300); Kumar, A Vijay (58847183300)","58674387900; 58674336600; 58674352500; 58674456300; 58847183300","Hybrid Algorithm for Real-Time Sign Language Detection System","2023","2023 International Conference on Network, Multimedia and Information Technology, NMITCON 2023","","","","","","","0","10.1109/NMITCON58196.2023.10276188","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175401238&doi=10.1109%2fNMITCON58196.2023.10276188&partnerID=40&md5=6e6b41d24a5b23eff2487655c209bf2b","Jain University, Bengaluru, India","Shrestha O.K., Jain University, Bengaluru, India; Khatiwada S., Jain University, Bengaluru, India; Ghimire A., Jain University, Bengaluru, India; Rajbhandari B., Jain University, Bengaluru, India; Kumar A.V., Jain University, Bengaluru, India","This research paper suggests a machine learning-based system designed to interpret sign languages in real-time from a video feed to help deaf and hard of hearing individuals overcome communication barriers. Sign languages employ hand gestures, facial expressions, and body language to convey ideas and meaning visually. Unfortunately, individuals with hearing impairments face communication difficulties, limited access to information and services, and social isolation. The proposed system captures the subject's gestures using a camera, which are then processed using a TensorFlow object detection API that predicts based on a pre-trained machine learning model. The system's methodology incorporates supervised learning, Single Shot MultiBox Detector (SSD) object detection algorithm, and the luminosity method for converting colour images to grayscale. For dataset creation, hand gesture image samples were captured and labelled using open-source graphical annotation software LabelImg, and the model was trained. The system proposed achieved an average accuracy of 95% and has the potential to improve communication and reduce marginalization for deaf and hard of hearing individuals.  © 2023 IEEE.","American Sign Language; Deep Learning; Image Recognition; Luminosity Method; Machine Learning; Object Detection; Sign Language; Single Shot MultiBox Detector; Supervised Learning","Audition; Deep learning; Learning algorithms; Learning systems; Luminance; Object detection; Object recognition; Open source software; Open systems; American sign language; Deep learning; Hard of hearings; Luminosity method; Machine-learning; Objects detection; Real- time; Sign language; Single shot multibox detector; Single-shot; Image recognition","","Institute of Electrical and Electronics Engineers Inc.","English","Int. Conf. Netw., Multimed. Inf. Technol., NMITCON","Conference paper","Final","","Scopus","2-s2.0-85175401238"
"Kumar D.S.; Swathi E.K.; Magisha S.; Priyavarshini M.; Sai Varshika L.; Gopinath N.","Kumar, D. Sathish (57211312840); Swathi, E.K. (58965582600); Magisha, S. (58964901400); Priyavarshini, M. (58965846700); Sai Varshika, L. (58965846800); Gopinath, N. (57221224179)","57211312840; 58965582600; 58964901400; 58965846700; 58965846800; 57221224179","Voiz: Automated Traffic Sign and Obstacle Detection Assistance using Tensorflow and CNN","2023","2023 Intelligent Computing and Control for Engineering and Business Systems, ICCEBS 2023","","","","","","","0","10.1109/ICCEBS58601.2023.10449320","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189176066&doi=10.1109%2fICCEBS58601.2023.10449320&partnerID=40&md5=87a92d183a61115f0b980dc8b041375b","Sri Sairam Engineering College, Computer Science and Engineering, Chennai, India","Kumar D.S., Sri Sairam Engineering College, Computer Science and Engineering, Chennai, India; Swathi E.K., Sri Sairam Engineering College, Computer Science and Engineering, Chennai, India; Magisha S., Sri Sairam Engineering College, Computer Science and Engineering, Chennai, India; Priyavarshini M., Sri Sairam Engineering College, Computer Science and Engineering, Chennai, India; Sai Varshika L., Sri Sairam Engineering College, Computer Science and Engineering, Chennai, India; Gopinath N., Sri Sairam Engineering College, Computer Science and Engineering, Chennai, India","The tremendous progress of society and the economy has made autos one of the most practical means of transportation for practically every family today. As a result, the road traffic environment is becoming more complex, necessitating the development of an intelligent voice-assisted application to govern driving operations based on data from traffic signs and the detection of real-time barriers. Vehicle cameras may collect photos of the road in real life, allowing for detection, identification of roadside hazards for the traffic signs. The driving system receives precise data thanks to the alerts the system issues to the driver in the form of simulated voice commands for the various conditions observed. In order to process the deep features inside the picture autonomously based on the training samples for the target identification, this project makes use of the deep learning open source library tensorflow. Tensorflow is a computer vision technique which helps us in detecting and tracing an object. The special attribute about TensorFlow is that it identifies the class of the obstacle (person, pothole, animal, object) and their location-specific coordinates. The trained model focuses on alerting the driver prior to the location on the basis of the traveling speed. The GTTS (google-text-to-speech) engine is used for the audio alert system. It takes text and turns them into spoken language. The estimated accuracy of the above system proves to be efficient as compared to the standard systems available by means of detection and assistance.  © 2023 IEEE.","","Deep learning; Object detection; Obstacle detectors; Roads and streets; Detection/identification; Driving operations; Driving systems; Means of transportations; Obstacles detection; Real- time; Road traffic environments; Systems issues; Traffic sign detection; Voice command; Traffic signs","","Institute of Electrical and Electronics Engineers Inc.","English","Intell. Comput. Control Eng. Bus. Syst., ICCEBS","Conference paper","Final","","Scopus","2-s2.0-85189176066"
